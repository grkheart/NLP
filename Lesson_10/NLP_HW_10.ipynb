{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-16T08:21:50.253681Z","iopub.execute_input":"2023-05-16T08:21:50.254046Z","iopub.status.idle":"2023-05-16T08:21:50.267385Z","shell.execute_reply.started":"2023-05-16T08:21:50.254018Z","shell.execute_reply":"2023-05-16T08:21:50.266306Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Машинный перевод. Модель seq2seq и механизм внимания\n\nРазобраться с моделью перевода (без механизма внимания) как она устроена, запустить для перевода с русского на английский (при желании можно взять другие пары языков)\nВ данном практическом задании напишу и обучу модель перевода с русского на английский\nна библиотеке pytorch. Добавлю в неё механизм внимания, так как это сложнее и интереснее,\nа также рекуррентную сеть энкодера сделаю двунаправленной.","metadata":{}},{"cell_type":"code","source":"pip install numpy","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:21:50.269565Z","iopub.execute_input":"2023-05-16T08:21:50.269897Z","iopub.status.idle":"2023-05-16T08:22:01.192637Z","shell.execute_reply.started":"2023-05-16T08:21:50.269866Z","shell.execute_reply":"2023-05-16T08:22:01.191340Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport unicodedata\nimport re\nimport numpy as np\nimport os\nimport io\nimport time\nimport conda","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:37:12.528367Z","iopub.execute_input":"2023-05-16T08:37:12.528738Z","iopub.status.idle":"2023-05-16T08:37:12.536584Z","shell.execute_reply.started":"2023-05-16T08:37:12.528701Z","shell.execute_reply":"2023-05-16T08:37:12.535662Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"### Download and prepare the dataset\n\nWe'll use a language dataset provided by http://www.manythings.org/anki/","metadata":{}},{"cell_type":"code","source":"# !wget http://www.manythings.org/anki/rus-eng.zip\n!wget http://www.manythings.org/anki/swe-eng.zip","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:22:04.079633Z","iopub.execute_input":"2023-05-16T08:22:04.080410Z","iopub.status.idle":"2023-05-16T08:22:05.297355Z","shell.execute_reply.started":"2023-05-16T08:22:04.080374Z","shell.execute_reply":"2023-05-16T08:22:05.296082Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2023-05-16 08:22:04--  http://www.manythings.org/anki/swe-eng.zip\nResolving www.manythings.org (www.manythings.org)... 173.254.30.110\nConnecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 744068 (727K) [application/zip]\nSaving to: ‘swe-eng.zip.3’\n\nswe-eng.zip.3       100%[===================>] 726.63K  --.-KB/s    in 0.1s    \n\n2023-05-16 08:22:05 (6.20 MB/s) - ‘swe-eng.zip.3’ saved [744068/744068]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# !mkdir rus-eng\n# !unzip rus-eng.zip -d rus-eng/\n!mkdir swe-eng\n!unzip swe-eng -d swe-eng/","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:22:05.299286Z","iopub.execute_input":"2023-05-16T08:22:05.299918Z","iopub.status.idle":"2023-05-16T08:22:45.840902Z","shell.execute_reply.started":"2023-05-16T08:22:05.299875Z","shell.execute_reply":"2023-05-16T08:22:45.839686Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘swe-eng’: File exists\nArchive:  swe-eng.zip\nreplace swe-eng/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/working/swe-eng -lah","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:18.357667Z","iopub.execute_input":"2023-05-16T08:23:18.358044Z","iopub.status.idle":"2023-05-16T08:23:19.382215Z","shell.execute_reply.started":"2023-05-16T08:23:18.358014Z","shell.execute_reply":"2023-05-16T08:23:19.381036Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"total 3.1M\ndrwxr-xr-x 2 root root 4.0K May 16 07:47 .\ndrwxr-xr-x 4 root root 4.0K May 16 08:22 ..\n-rw-r--r-- 1 root root 1.5K Apr  2 03:16 _about.txt\n-rw-r--r-- 1 root root 3.0M Apr  2 03:16 swe.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Download the file\npath_to_file = \"/kaggle/working/swe-eng/swe.txt\"","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:25.236684Z","iopub.execute_input":"2023-05-16T08:23:25.237061Z","iopub.status.idle":"2023-05-16T08:23:25.242157Z","shell.execute_reply.started":"2023-05-16T08:23:25.237032Z","shell.execute_reply":"2023-05-16T08:23:25.241130Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def preprocess_sentence(w):\n  w = w.lower().strip()\n\n  # creating a space between a word and the punctuation following it\n  # eg: \"he is a boy.\" => \"he is a boy .\"\n  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n  w = re.sub(r'[\" \"]+', \" \", w)\n\n  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n\n  w = w.strip()\n\n  # adding a start and an end token to the sentence\n  # so that the model know when to start and stop predicting.\n  w = '< start > ' + w + ' <end >'\n  return w","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:26.611795Z","iopub.execute_input":"2023-05-16T08:23:26.612178Z","iopub.status.idle":"2023-05-16T08:23:26.618854Z","shell.execute_reply.started":"2023-05-16T08:23:26.612150Z","shell.execute_reply":"2023-05-16T08:23:26.617840Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"preprocess_sentence(\"I can't go.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:30.476955Z","iopub.execute_input":"2023-05-16T08:23:30.477810Z","iopub.status.idle":"2023-05-16T08:23:30.485309Z","shell.execute_reply.started":"2023-05-16T08:23:30.477773Z","shell.execute_reply":"2023-05-16T08:23:30.484258Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"\"< start > i can't go . <end >\""},"metadata":{}}]},{"cell_type":"code","source":"# 1. Remove the accents\n# 2. Clean the sentences\n# 3. Return word pairs in the format: [ENG, RUS]\ndef create_dataset(path, num_examples):\n  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n\n  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n\n  return zip(*word_pairs)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:35.170708Z","iopub.execute_input":"2023-05-16T08:23:35.171548Z","iopub.status.idle":"2023-05-16T08:23:35.178087Z","shell.execute_reply.started":"2023-05-16T08:23:35.171515Z","shell.execute_reply":"2023-05-16T08:23:35.177153Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"en, swe = create_dataset(path_to_file, None)\nprint(en[0])\nprint(swe[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:38.604790Z","iopub.execute_input":"2023-05-16T08:23:38.605205Z","iopub.status.idle":"2023-05-16T08:23:39.705247Z","shell.execute_reply.started":"2023-05-16T08:23:38.605175Z","shell.execute_reply":"2023-05-16T08:23:39.704234Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"< start > go . <end >\n< start > g . <end >\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize(lang):\n  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n      filters='')\n  lang_tokenizer.fit_on_texts(lang)\n\n  tensor = lang_tokenizer.texts_to_sequences(lang)\n\n  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n                                                         padding='post')\n\n  return tensor, lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:48.199876Z","iopub.execute_input":"2023-05-16T08:23:48.200262Z","iopub.status.idle":"2023-05-16T08:23:48.205480Z","shell.execute_reply.started":"2023-05-16T08:23:48.200219Z","shell.execute_reply":"2023-05-16T08:23:48.204507Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def load_dataset(path, num_examples=None):\n  # creating cleaned input, output pairs\n  targ_lang, inp_lang = create_dataset(path, num_examples)\n\n  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n\n  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:51.212645Z","iopub.execute_input":"2023-05-16T08:23:51.213020Z","iopub.status.idle":"2023-05-16T08:23:51.218737Z","shell.execute_reply.started":"2023-05-16T08:23:51.212989Z","shell.execute_reply":"2023-05-16T08:23:51.217607Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Limit the size of the dataset to experiment faster (optional)","metadata":{}},{"cell_type":"code","source":"len(en), len(swe)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:54.771207Z","iopub.execute_input":"2023-05-16T08:23:54.771569Z","iopub.status.idle":"2023-05-16T08:23:54.780720Z","shell.execute_reply.started":"2023-05-16T08:23:54.771543Z","shell.execute_reply":"2023-05-16T08:23:54.779767Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(23267, 23267)"},"metadata":{}}]},{"cell_type":"code","source":"# Try experimenting with the size of that dataset\nnum_examples = 100000\ninput_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n\n# Calculate max_length of the target tensors\nmax_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:23:57.756971Z","iopub.execute_input":"2023-05-16T08:23:57.757377Z","iopub.status.idle":"2023-05-16T08:23:59.709512Z","shell.execute_reply.started":"2023-05-16T08:23:57.757345Z","shell.execute_reply":"2023-05-16T08:23:59.708484Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Creating training and validation sets using an 80-20 split\ninput_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n\n# Show length\nprint(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:01.611724Z","iopub.execute_input":"2023-05-16T08:24:01.612108Z","iopub.status.idle":"2023-05-16T08:24:01.631557Z","shell.execute_reply.started":"2023-05-16T08:24:01.612067Z","shell.execute_reply":"2023-05-16T08:24:01.630566Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"18613 18613 4654 4654\n","output_type":"stream"}]},{"cell_type":"code","source":"def convert(lang, tensor):\n  for t in tensor:\n    if t!=0:\n      print (\"%d ----> %s\" % (t, lang.index_word[t]))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:07.712998Z","iopub.execute_input":"2023-05-16T08:24:07.713908Z","iopub.status.idle":"2023-05-16T08:24:07.719055Z","shell.execute_reply.started":"2023-05-16T08:24:07.713871Z","shell.execute_reply":"2023-05-16T08:24:07.718039Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print (\"Input Language; index to word mapping\")\nconvert(inp_lang, input_tensor_train[0])\nprint ()\nprint (\"Target Language; index to word mapping\")\nconvert(targ_lang, target_tensor_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:09.931664Z","iopub.execute_input":"2023-05-16T08:24:09.932020Z","iopub.status.idle":"2023-05-16T08:24:09.938401Z","shell.execute_reply.started":"2023-05-16T08:24:09.931992Z","shell.execute_reply":"2023-05-16T08:24:09.937477Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Input Language; index to word mapping\n2 ----> <\n3 ----> start\n1 ----> >\n7 ----> jag\n6 ----> r\n102 ----> lite\n5079 ----> uppskakad\n5 ----> .\n4 ----> <end\n1 ----> >\n\nTarget Language; index to word mapping\n3 ----> <\n2 ----> start\n1 ----> >\n29 ----> i'm\n12 ----> a\n239 ----> little\n862 ----> shook\n63 ----> up\n5 ----> .\n4 ----> <end\n1 ----> >\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Create a tf.data dataset","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = len(input_tensor_train)\nBATCH_SIZE = 64\nsteps_per_epoch = len(input_tensor_train)//BATCH_SIZE\nembedding_dim = 300\nunits = 1024\nvocab_inp_size = len(inp_lang.word_index)+1\nvocab_tar_size = len(targ_lang.word_index)+1\n\ndataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:16.170600Z","iopub.execute_input":"2023-05-16T08:24:16.171333Z","iopub.status.idle":"2023-05-16T08:24:16.186645Z","shell.execute_reply.started":"2023-05-16T08:24:16.171290Z","shell.execute_reply":"2023-05-16T08:24:16.185618Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"example_input_batch, example_target_batch = next(iter(dataset))\nexample_input_batch.shape, example_target_batch.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:18.650770Z","iopub.execute_input":"2023-05-16T08:24:18.651168Z","iopub.status.idle":"2023-05-16T08:24:18.712597Z","shell.execute_reply.started":"2023-05-16T08:24:18.651132Z","shell.execute_reply":"2023-05-16T08:24:18.711393Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(TensorShape([64, 96]), TensorShape([64, 78]))"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n    super(Encoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.enc_units = enc_units\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    self.gru = tf.keras.layers.GRU(self.enc_units,\n                                   return_sequences=False,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n    \n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, state = self.gru(x, initial_state = hidden)\n    return state\n\n  def initialize_hidden_state(self):\n    return tf.zeros((self.batch_sz, self.enc_units))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:21.989018Z","iopub.execute_input":"2023-05-16T08:24:21.989886Z","iopub.status.idle":"2023-05-16T08:24:21.998283Z","shell.execute_reply.started":"2023-05-16T08:24:21.989849Z","shell.execute_reply":"2023-05-16T08:24:21.997173Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n\n# sample input\nsample_hidden = encoder.initialize_hidden_state()\nsample_hidden = encoder(example_input_batch, sample_hidden)\n# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:27.597993Z","iopub.execute_input":"2023-05-16T08:24:27.598394Z","iopub.status.idle":"2023-05-16T08:24:27.630839Z","shell.execute_reply.started":"2023-05-16T08:24:27.598366Z","shell.execute_reply":"2023-05-16T08:24:27.629805Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Encoder Hidden state shape: (batch size, units) (64, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n    super(Decoder, self).__init__()\n    self.batch_sz = batch_sz\n    self.dec_units = dec_units\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    self.gru = tf.keras.layers.GRU(self.dec_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n    self.fc = tf.keras.layers.Dense(vocab_size)\n\n  def call(self, x, hidden):\n    # enc_output shape == (batch_size, max_length, hidden_size)\n\n    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n    x = self.embedding(x)\n\n    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n\n    # passing the concatenated vector to the GRU\n    output, state = self.gru(x, initial_state=hidden)\n\n    # output shape == (batch_size * 1, hidden_size)\n    output = tf.reshape(output, (-1, output.shape[2]))\n\n    # output shape == (batch_size, vocab)\n    x = self.fc(output)\n\n    return x, state","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:35.749532Z","iopub.execute_input":"2023-05-16T08:24:35.749897Z","iopub.status.idle":"2023-05-16T08:24:35.759036Z","shell.execute_reply.started":"2023-05-16T08:24:35.749868Z","shell.execute_reply":"2023-05-16T08:24:35.758013Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n\ndecoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n                                      sample_hidden)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:38.396798Z","iopub.execute_input":"2023-05-16T08:24:38.397200Z","iopub.status.idle":"2023-05-16T08:24:38.431005Z","shell.execute_reply.started":"2023-05-16T08:24:38.397169Z","shell.execute_reply":"2023-05-16T08:24:38.429867Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"decoder_sample_x.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:42.794812Z","iopub.execute_input":"2023-05-16T08:24:42.795235Z","iopub.status.idle":"2023-05-16T08:24:42.800970Z","shell.execute_reply.started":"2023-05-16T08:24:42.795204Z","shell.execute_reply":"2023-05-16T08:24:42.799947Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 5865])"},"metadata":{}}]},{"cell_type":"code","source":"decoder_sample_h.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:45.398999Z","iopub.execute_input":"2023-05-16T08:24:45.399399Z","iopub.status.idle":"2023-05-16T08:24:45.405399Z","shell.execute_reply.started":"2023-05-16T08:24:45.399367Z","shell.execute_reply":"2023-05-16T08:24:45.404236Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 1024])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Define the optimizer and the loss function","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\n\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  loss_ = loss_object(real, pred)\n\n  mask = tf.cast(mask, dtype=loss_.dtype)\n  loss_ *= mask\n\n  return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:24:48.308982Z","iopub.execute_input":"2023-05-16T08:24:48.309728Z","iopub.status.idle":"2023-05-16T08:24:48.318505Z","shell.execute_reply.started":"2023-05-16T08:24:48.309692Z","shell.execute_reply":"2023-05-16T08:24:48.317430Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Checkpoints (Object-based saving)","metadata":{}},{"cell_type":"code","source":"checkpoint_dir = './kaggle/working/swe-eng/training_nmt_checkpoints'\n\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n\ncheckpoint = tf.train.Checkpoint(optimizer=optimizer,\n                                 encoder=encoder,\n                                 decoder=decoder)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:39:44.931764Z","iopub.execute_input":"2023-05-16T08:39:44.932171Z","iopub.status.idle":"2023-05-16T08:39:44.942727Z","shell.execute_reply.started":"2023-05-16T08:39:44.932140Z","shell.execute_reply":"2023-05-16T08:39:44.941835Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(inp, targ, enc_hidden):\n  loss = 0\n\n  with tf.GradientTape() as tape:\n    enc_hidden = encoder(inp, enc_hidden)\n\n    dec_hidden = enc_hidden\n\n    dec_input = tf.expand_dims([targ_lang.word_index['start']] * BATCH_SIZE, 1)\n\n    # Teacher forcing - feeding the target as the next input\n    for t in range(1, targ.shape[1]):\n      # passing enc_output to the decoder\n      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n      loss += loss_function(targ[:, t], predictions)\n\n      # using teacher forcing\n      dec_input = tf.expand_dims(targ[:, t], 1)\n\n  batch_loss = (loss / int(targ.shape[1]))\n\n  variables = encoder.trainable_variables + decoder.trainable_variables\n\n  gradients = tape.gradient(loss, variables)\n\n  optimizer.apply_gradients(zip(gradients, variables))\n\n  return batch_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:58:13.731872Z","iopub.execute_input":"2023-05-16T08:58:13.732275Z","iopub.status.idle":"2023-05-16T08:58:13.743680Z","shell.execute_reply.started":"2023-05-16T08:58:13.732225Z","shell.execute_reply":"2023-05-16T08:58:13.742735Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 50\n\nfor epoch in range(EPOCHS):\n    start = time.time()\n\n    enc_hidden = encoder.initialize_hidden_state()\n    total_loss = 0\n\n    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n        batch_loss = train_step(inp, targ, enc_hidden)\n        total_loss += batch_loss\n\n        if batch % 100 == 0:\n          print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n                                                       batch,\n                                                       batch_loss.numpy()))\n  # saving (checkpoint) the model every 2 epochs\n    if (epoch + 1) % 2 == 0:\n        checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n                                        total_loss / steps_per_epoch))\n\n    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T08:58:34.919004Z","iopub.execute_input":"2023-05-16T08:58:34.919721Z","iopub.status.idle":"2023-05-16T10:04:20.457639Z","shell.execute_reply.started":"2023-05-16T08:58:34.919682Z","shell.execute_reply":"2023-05-16T10:04:20.456534Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"Epoch 1 Batch 0 Loss 0.1070\nEpoch 1 Batch 100 Loss 0.1016\nEpoch 1 Batch 200 Loss 0.1254\nEpoch 1 Loss 0.1082\nTime taken for 1 epoch 129.32504415512085 sec\n\nEpoch 2 Batch 0 Loss 0.0675\nEpoch 2 Batch 100 Loss 0.0800\nEpoch 2 Batch 200 Loss 0.0777\nEpoch 2 Loss 0.0775\nTime taken for 1 epoch 78.51390147209167 sec\n\nEpoch 3 Batch 0 Loss 0.0525\nEpoch 3 Batch 100 Loss 0.0549\nEpoch 3 Batch 200 Loss 0.0507\nEpoch 3 Loss 0.0553\nTime taken for 1 epoch 78.05510067939758 sec\n\nEpoch 4 Batch 0 Loss 0.0314\nEpoch 4 Batch 100 Loss 0.0401\nEpoch 4 Batch 200 Loss 0.0435\nEpoch 4 Loss 0.0393\nTime taken for 1 epoch 78.296635389328 sec\n\nEpoch 5 Batch 0 Loss 0.0249\nEpoch 5 Batch 100 Loss 0.0266\nEpoch 5 Batch 200 Loss 0.0291\nEpoch 5 Loss 0.0283\nTime taken for 1 epoch 77.72727608680725 sec\n\nEpoch 6 Batch 0 Loss 0.0160\nEpoch 6 Batch 100 Loss 0.0204\nEpoch 6 Batch 200 Loss 0.0226\nEpoch 6 Loss 0.0212\nTime taken for 1 epoch 78.41791415214539 sec\n\nEpoch 7 Batch 0 Loss 0.0200\nEpoch 7 Batch 100 Loss 0.0121\nEpoch 7 Batch 200 Loss 0.0197\nEpoch 7 Loss 0.0162\nTime taken for 1 epoch 78.09554862976074 sec\n\nEpoch 8 Batch 0 Loss 0.0108\nEpoch 8 Batch 100 Loss 0.0148\nEpoch 8 Batch 200 Loss 0.0097\nEpoch 8 Loss 0.0127\nTime taken for 1 epoch 78.0092716217041 sec\n\nEpoch 9 Batch 0 Loss 0.0088\nEpoch 9 Batch 100 Loss 0.0078\nEpoch 9 Batch 200 Loss 0.0126\nEpoch 9 Loss 0.0104\nTime taken for 1 epoch 77.80696892738342 sec\n\nEpoch 10 Batch 0 Loss 0.0079\nEpoch 10 Batch 100 Loss 0.0106\nEpoch 10 Batch 200 Loss 0.0046\nEpoch 10 Loss 0.0091\nTime taken for 1 epoch 78.58547735214233 sec\n\nEpoch 11 Batch 0 Loss 0.0073\nEpoch 11 Batch 100 Loss 0.0057\nEpoch 11 Batch 200 Loss 0.0111\nEpoch 11 Loss 0.0081\nTime taken for 1 epoch 78.1595368385315 sec\n\nEpoch 12 Batch 0 Loss 0.0066\nEpoch 12 Batch 100 Loss 0.0070\nEpoch 12 Batch 200 Loss 0.0099\nEpoch 12 Loss 0.0075\nTime taken for 1 epoch 78.29273438453674 sec\n\nEpoch 13 Batch 0 Loss 0.0051\nEpoch 13 Batch 100 Loss 0.0033\nEpoch 13 Batch 200 Loss 0.0121\nEpoch 13 Loss 0.0075\nTime taken for 1 epoch 78.30681657791138 sec\n\nEpoch 14 Batch 0 Loss 0.0043\nEpoch 14 Batch 100 Loss 0.0087\nEpoch 14 Batch 200 Loss 0.0115\nEpoch 14 Loss 0.0078\nTime taken for 1 epoch 77.99828028678894 sec\n\nEpoch 15 Batch 0 Loss 0.0064\nEpoch 15 Batch 100 Loss 0.0096\nEpoch 15 Batch 200 Loss 0.0087\nEpoch 15 Loss 0.0084\nTime taken for 1 epoch 77.71033024787903 sec\n\nEpoch 16 Batch 0 Loss 0.0044\nEpoch 16 Batch 100 Loss 0.0070\nEpoch 16 Batch 200 Loss 0.0117\nEpoch 16 Loss 0.0091\nTime taken for 1 epoch 78.36487412452698 sec\n\nEpoch 17 Batch 0 Loss 0.0054\nEpoch 17 Batch 100 Loss 0.0093\nEpoch 17 Batch 200 Loss 0.0063\nEpoch 17 Loss 0.0088\nTime taken for 1 epoch 77.90664100646973 sec\n\nEpoch 18 Batch 0 Loss 0.0072\nEpoch 18 Batch 100 Loss 0.0079\nEpoch 18 Batch 200 Loss 0.0060\nEpoch 18 Loss 0.0077\nTime taken for 1 epoch 77.89022636413574 sec\n\nEpoch 19 Batch 0 Loss 0.0062\nEpoch 19 Batch 100 Loss 0.0052\nEpoch 19 Batch 200 Loss 0.0115\nEpoch 19 Loss 0.0067\nTime taken for 1 epoch 77.71823358535767 sec\n\nEpoch 20 Batch 0 Loss 0.0040\nEpoch 20 Batch 100 Loss 0.0044\nEpoch 20 Batch 200 Loss 0.0073\nEpoch 20 Loss 0.0058\nTime taken for 1 epoch 77.90137934684753 sec\n\nEpoch 21 Batch 0 Loss 0.0024\nEpoch 21 Batch 100 Loss 0.0035\nEpoch 21 Batch 200 Loss 0.0136\nEpoch 21 Loss 0.0058\nTime taken for 1 epoch 77.64397692680359 sec\n\nEpoch 22 Batch 0 Loss 0.0057\nEpoch 22 Batch 100 Loss 0.0027\nEpoch 22 Batch 200 Loss 0.0048\nEpoch 22 Loss 0.0054\nTime taken for 1 epoch 77.91356754302979 sec\n\nEpoch 23 Batch 0 Loss 0.0035\nEpoch 23 Batch 100 Loss 0.0045\nEpoch 23 Batch 200 Loss 0.0054\nEpoch 23 Loss 0.0055\nTime taken for 1 epoch 77.89573907852173 sec\n\nEpoch 24 Batch 0 Loss 0.0042\nEpoch 24 Batch 100 Loss 0.0096\nEpoch 24 Batch 200 Loss 0.0037\nEpoch 24 Loss 0.0056\nTime taken for 1 epoch 77.85496068000793 sec\n\nEpoch 25 Batch 0 Loss 0.0048\nEpoch 25 Batch 100 Loss 0.0053\nEpoch 25 Batch 200 Loss 0.0104\nEpoch 25 Loss 0.0059\nTime taken for 1 epoch 77.65419125556946 sec\n\nEpoch 26 Batch 0 Loss 0.0085\nEpoch 26 Batch 100 Loss 0.0071\nEpoch 26 Batch 200 Loss 0.0068\nEpoch 26 Loss 0.0079\nTime taken for 1 epoch 77.85658836364746 sec\n\nEpoch 27 Batch 0 Loss 0.0063\nEpoch 27 Batch 100 Loss 0.0131\nEpoch 27 Batch 200 Loss 0.0101\nEpoch 27 Loss 0.0103\nTime taken for 1 epoch 77.61660623550415 sec\n\nEpoch 28 Batch 0 Loss 0.0107\nEpoch 28 Batch 100 Loss 0.0123\nEpoch 28 Batch 200 Loss 0.0068\nEpoch 28 Loss 0.0097\nTime taken for 1 epoch 78.1995804309845 sec\n\nEpoch 29 Batch 0 Loss 0.0070\nEpoch 29 Batch 100 Loss 0.0046\nEpoch 29 Batch 200 Loss 0.0073\nEpoch 29 Loss 0.0070\nTime taken for 1 epoch 77.74265384674072 sec\n\nEpoch 30 Batch 0 Loss 0.0064\nEpoch 30 Batch 100 Loss 0.0087\nEpoch 30 Batch 200 Loss 0.0026\nEpoch 30 Loss 0.0057\nTime taken for 1 epoch 77.96149110794067 sec\n\nEpoch 31 Batch 0 Loss 0.0036\nEpoch 31 Batch 100 Loss 0.0035\nEpoch 31 Batch 200 Loss 0.0026\nEpoch 31 Loss 0.0048\nTime taken for 1 epoch 77.557687997818 sec\n\nEpoch 32 Batch 0 Loss 0.0034\nEpoch 32 Batch 100 Loss 0.0013\nEpoch 32 Batch 200 Loss 0.0109\nEpoch 32 Loss 0.0045\nTime taken for 1 epoch 77.85150337219238 sec\n\nEpoch 33 Batch 0 Loss 0.0011\nEpoch 33 Batch 100 Loss 0.0027\nEpoch 33 Batch 200 Loss 0.0038\nEpoch 33 Loss 0.0042\nTime taken for 1 epoch 77.52322673797607 sec\n\nEpoch 34 Batch 0 Loss 0.0013\nEpoch 34 Batch 100 Loss 0.0086\nEpoch 34 Batch 200 Loss 0.0036\nEpoch 34 Loss 0.0043\nTime taken for 1 epoch 77.81377577781677 sec\n\nEpoch 35 Batch 0 Loss 0.0027\nEpoch 35 Batch 100 Loss 0.0060\nEpoch 35 Batch 200 Loss 0.0060\nEpoch 35 Loss 0.0044\nTime taken for 1 epoch 77.52629923820496 sec\n\nEpoch 36 Batch 0 Loss 0.0027\nEpoch 36 Batch 100 Loss 0.0040\nEpoch 36 Batch 200 Loss 0.0109\nEpoch 36 Loss 0.0048\nTime taken for 1 epoch 77.78841257095337 sec\n\nEpoch 37 Batch 0 Loss 0.0047\nEpoch 37 Batch 100 Loss 0.0028\nEpoch 37 Batch 200 Loss 0.0046\nEpoch 37 Loss 0.0057\nTime taken for 1 epoch 77.50755429267883 sec\n\nEpoch 38 Batch 0 Loss 0.0036\nEpoch 38 Batch 100 Loss 0.0086\nEpoch 38 Batch 200 Loss 0.0097\nEpoch 38 Loss 0.0096\nTime taken for 1 epoch 77.77796745300293 sec\n\nEpoch 39 Batch 0 Loss 0.0088\nEpoch 39 Batch 100 Loss 0.0139\nEpoch 39 Batch 200 Loss 0.0077\nEpoch 39 Loss 0.0114\nTime taken for 1 epoch 77.54113411903381 sec\n\nEpoch 40 Batch 0 Loss 0.0089\nEpoch 40 Batch 100 Loss 0.0086\nEpoch 40 Batch 200 Loss 0.0076\nEpoch 40 Loss 0.0082\nTime taken for 1 epoch 78.00176000595093 sec\n\nEpoch 41 Batch 0 Loss 0.0043\nEpoch 41 Batch 100 Loss 0.0028\nEpoch 41 Batch 200 Loss 0.0035\nEpoch 41 Loss 0.0056\nTime taken for 1 epoch 77.50735640525818 sec\n\nEpoch 42 Batch 0 Loss 0.0023\nEpoch 42 Batch 100 Loss 0.0020\nEpoch 42 Batch 200 Loss 0.0034\nEpoch 42 Loss 0.0045\nTime taken for 1 epoch 77.98409724235535 sec\n\nEpoch 43 Batch 0 Loss 0.0028\nEpoch 43 Batch 100 Loss 0.0036\nEpoch 43 Batch 200 Loss 0.0058\nEpoch 43 Loss 0.0041\nTime taken for 1 epoch 77.77112245559692 sec\n\nEpoch 44 Batch 0 Loss 0.0034\nEpoch 44 Batch 100 Loss 0.0025\nEpoch 44 Batch 200 Loss 0.0117\nEpoch 44 Loss 0.0039\nTime taken for 1 epoch 77.71385288238525 sec\n\nEpoch 45 Batch 0 Loss 0.0042\nEpoch 45 Batch 100 Loss 0.0032\nEpoch 45 Batch 200 Loss 0.0033\nEpoch 45 Loss 0.0039\nTime taken for 1 epoch 77.53143620491028 sec\n\nEpoch 46 Batch 0 Loss 0.0005\nEpoch 46 Batch 100 Loss 0.0045\nEpoch 46 Batch 200 Loss 0.0071\nEpoch 46 Loss 0.0040\nTime taken for 1 epoch 77.77687644958496 sec\n\nEpoch 47 Batch 0 Loss 0.0022\nEpoch 47 Batch 100 Loss 0.0027\nEpoch 47 Batch 200 Loss 0.0056\nEpoch 47 Loss 0.0042\nTime taken for 1 epoch 77.498699426651 sec\n\nEpoch 48 Batch 0 Loss 0.0056\nEpoch 48 Batch 100 Loss 0.0007\nEpoch 48 Batch 200 Loss 0.0055\nEpoch 48 Loss 0.0045\nTime taken for 1 epoch 78.0681962966919 sec\n\nEpoch 49 Batch 0 Loss 0.0064\nEpoch 49 Batch 100 Loss 0.0087\nEpoch 49 Batch 200 Loss 0.0031\nEpoch 49 Loss 0.0056\nTime taken for 1 epoch 77.58746933937073 sec\n\nEpoch 50 Batch 0 Loss 0.0073\nEpoch 50 Batch 100 Loss 0.0099\nEpoch 50 Batch 200 Loss 0.0077\nEpoch 50 Loss 0.0111\nTime taken for 1 epoch 77.77825284004211 sec\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Translate\n\n* The evaluate function is similar to the training loop, except we don't use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n* Stop predicting when the model predicts the end token.\n* And store the attention weights for every time step.\n\nNote: The encoder output is calculated only once for one input.","metadata":{}},{"cell_type":"code","source":"def evaluate(sentence):\n    attention_plot = np.zeros((max_length_targ, max_length_inp))\n\n    sentence = preprocess_sentence(sentence)\n\n    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n                                                         maxlen=max_length_inp,\n                                                         padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n\n    result = ''\n\n    hidden = [tf.zeros((1, units))]\n    enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([targ_lang.word_index['start']], 0)\n\n    for t in range(max_length_targ):\n        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n        # storing the attention weights to plot later on\n        predicted_id = tf.argmax(predictions[0]).numpy()\n        result += targ_lang.index_word[predicted_id] + ' '\n\n        if targ_lang.index_word[predicted_id] == 'end':\n            return result, sentence\n\n        # the predicted ID is fed back into the model\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return result, sentence","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:12.365758Z","iopub.execute_input":"2023-05-16T10:14:12.366139Z","iopub.status.idle":"2023-05-16T10:14:12.375548Z","shell.execute_reply.started":"2023-05-16T10:14:12.366089Z","shell.execute_reply":"2023-05-16T10:14:12.374620Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"def translate(sentence):\n  result, sentence = evaluate(sentence)\n\n  print('Input: %s' % (sentence))\n  print('Predicted translation: {}'.format(result))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:15.493684Z","iopub.execute_input":"2023-05-16T10:14:15.494087Z","iopub.status.idle":"2023-05-16T10:14:15.499223Z","shell.execute_reply.started":"2023-05-16T10:14:15.494041Z","shell.execute_reply":"2023-05-16T10:14:15.498259Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"### Restore the latest checkpoint and test","metadata":{}},{"cell_type":"code","source":"# restoring the latest checkpoint in checkpoint_dir\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:18.534023Z","iopub.execute_input":"2023-05-16T10:14:18.535046Z","iopub.status.idle":"2023-05-16T10:14:18.698074Z","shell.execute_reply.started":"2023-05-16T10:14:18.535000Z","shell.execute_reply":"2023-05-16T10:14:18.697068Z"},"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7da51fbaeda0>"},"metadata":{}}]},{"cell_type":"code","source":"translate('Det är trevligt här.')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:20.679677Z","iopub.execute_input":"2023-05-16T10:14:20.680831Z","iopub.status.idle":"2023-05-16T10:14:21.249302Z","shell.execute_reply.started":"2023-05-16T10:14:20.680789Z","shell.execute_reply":"2023-05-16T10:14:21.248312Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"Input: < start > det r trevligt h r . <end >\nPredicted translation: start > this is the matter . <end > over is here . <end > it is on fire . <end > over it is . <end > it is on monday . <end > it was on fire . <end > it is out of them . <end > over one hundred . <end > it is a try . <end > it was on a front of time . <end > it is on fire . \n","output_type":"stream"}]},{"cell_type":"code","source":"translate('Jag kommer inte att kunna gå.')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:24.599851Z","iopub.execute_input":"2023-05-16T10:14:24.600247Z","iopub.status.idle":"2023-05-16T10:14:25.160837Z","shell.execute_reply.started":"2023-05-16T10:14:24.600204Z","shell.execute_reply":"2023-05-16T10:14:25.159709Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"Input: < start > jag kommer inte att kunna g . <end >\nPredicted translation: start > i'm not going to go . <end > i'm here . <end > i'm here . <end > do you want ? <end > it is fun . <end > over you . <end > might do the matter . <end > over one break . <end > over you ready ? <end > it was around for you . <end > it is a short designed for me to look . <end > it is \n","output_type":"stream"}]},{"cell_type":"code","source":"translate(u'Är du fortfarande hemma?')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:26.999854Z","iopub.execute_input":"2023-05-16T10:14:27.000258Z","iopub.status.idle":"2023-05-16T10:14:27.558808Z","shell.execute_reply.started":"2023-05-16T10:14:27.000214Z","shell.execute_reply":"2023-05-16T10:14:27.557822Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"Input: < start > r du fortfarande hemma ? <end >\nPredicted translation: start > are you still at home ? <end > it could be right . <end > it was under night . <end > it was a day . <end > it's on better . <end > does a practice of them are around . <end > it was on for a list . <end > it is on a man . <end > it is a mistake on their first floor . <end > it does . \n","output_type":"stream"}]},{"cell_type":"code","source":"translate(u'Är du fortfarande hemma?')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:29.079800Z","iopub.execute_input":"2023-05-16T10:14:29.080174Z","iopub.status.idle":"2023-05-16T10:14:29.635310Z","shell.execute_reply.started":"2023-05-16T10:14:29.080143Z","shell.execute_reply":"2023-05-16T10:14:29.634142Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"Input: < start > r du fortfarande hemma ? <end >\nPredicted translation: start > are you still at home ? <end > it could be right . <end > it was under night . <end > it was a day . <end > it's on better . <end > does a practice of them are around . <end > it was on for a list . <end > it is on a man . <end > it is a mistake on their first floor . <end > it does . \n","output_type":"stream"}]},{"cell_type":"code","source":"translate(u'Prova detta.')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:31.960277Z","iopub.execute_input":"2023-05-16T10:14:31.960632Z","iopub.status.idle":"2023-05-16T10:14:32.505259Z","shell.execute_reply.started":"2023-05-16T10:14:31.960604Z","shell.execute_reply":"2023-05-16T10:14:32.504165Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"Input: < start > prova detta . <end >\nPredicted translation: start > don't do it . <end > this is black . <end > it was seems to be . <end > it set himself . <end > it was getting first . <end > it was raining heavily . <end > it is about a look designed for him . <end > it was about it . <end > it is about that purpose such over . <end > it is . <end > it was seems \n","output_type":"stream"}]},{"cell_type":"code","source":"translate(u'Jag älskar det när det snöar.')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:35.573814Z","iopub.execute_input":"2023-05-16T10:14:35.574194Z","iopub.status.idle":"2023-05-16T10:14:36.124822Z","shell.execute_reply.started":"2023-05-16T10:14:35.574166Z","shell.execute_reply":"2023-05-16T10:14:36.123785Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"Input: < start > jag lskar det n r det sn ar . <end >\nPredicted translation: start > i love that dress . <end > it was that way that one giant leap for mankind . <end > it is a difficult own mistake . <end > it was raining heavily . <end > it is about a dream . <end > it is a look at white . <end > it is as a look designed for over . <end > it is a difficult way . <end > it is a difficult \n","output_type":"stream"}]},{"cell_type":"code","source":"translate(u'Jag gör aldrig det.')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T10:14:38.879945Z","iopub.execute_input":"2023-05-16T10:14:38.880736Z","iopub.status.idle":"2023-05-16T10:14:39.437588Z","shell.execute_reply.started":"2023-05-16T10:14:38.880696Z","shell.execute_reply":"2023-05-16T10:14:39.436624Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"Input: < start > jag g r aldrig det . <end >\nPredicted translation: start > i never do it . <end > it does . <end > it is a difficult question . <end > it is a way . <end > it is . <end > tom is over a car . <end > it might . <end > it is a look . <end > it was saying . <end > it is . <end > it's a better designed for that purpose such a website designed for them \n","output_type":"stream"}]}]}